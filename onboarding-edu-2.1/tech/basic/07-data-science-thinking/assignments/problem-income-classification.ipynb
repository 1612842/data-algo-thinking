{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Information *\n",
    "\n",
    "Extraction was done by Barry Becker from the 1994 Census database. <br>\n",
    "A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)) \n",
    "\n",
    "**Prediction task is to determine whether a person makes over 50K a year.** \n",
    "\n",
    "<sub>*Dua, D. and Karra Taniskidou, E. (2017). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.*</sub>\n",
    "\n",
    "** Attribute Information**\n",
    "\n",
    "*Please take a look at **\"detail.html\"** for further details.*\n",
    "\n",
    "**Targets:**\n",
    "\n",
    "> **>50K** or **<=50K**. \n",
    "\n",
    "**Listing of features:**\n",
    "\n",
    "* **age:** continuous. \n",
    "* **workclass:** Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. \n",
    "* **fnlwgt:** continuous. \n",
    "* **education:** Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. \n",
    "* **education-num:** continuous. \n",
    "* **marital-status:** Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. \n",
    "* **occupation:** Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. \n",
    "* **relationship:** Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. \n",
    "* **race:** White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. \n",
    "* **sex:** Female, Male. \n",
    "* **capital-gain:** continuous. \n",
    "* **capital-loss:** continuous. \n",
    "* **hours-per-week:** continuous. \n",
    "* **native-country:** United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aims\n",
    "\n",
    "**Author: YenNLH**\n",
    "\n",
    "Welcome to the first problem set of Data & Artifical Intelligence Lab.\n",
    "\n",
    "**In the scope of this task**, you are assigned to work on the dataset mentioned above. By dealing with this toy dataset, you are supposed to get acquainted with (for those who have never touched such type of data before) or show off ***your problem solving skills on data combining of categorical and numerical attributes***. \n",
    "\n",
    "**Why is it selected?** Basically, you are joining into and becoming a *quick-witted and helpful member* of **ZaloPay**. And of course, the most common and abundant data in the fintech system is all about categories and numbers. Thus, at the very first beginning, this data is quite appropriate for you to demonstrate your qualifications.\n",
    "\n",
    "The problem set will ask you to give as much as possible your effort on **covering all steps that you have to accomplish to exploit raw data from scratch in practice**. *The basic and suggested process is desribed concisely as bellow*. However, I encourage you to propose your own idea for adding/changing/improving it then having a better result with the assigned data. *Please bear in mind that any of your intuitive ideas should be convincing and have a certain contribution to your progress*.\n",
    "\n",
    "The requirement has **3 skill levels** including * **[B]**asic, **[I]**ntermediate and **[A]**dvanced*. Please freely **choose the desirable and suitable level for yourself**. *Furthermore, if you seriously destine data science to be your career, try hard with the highest level that you can achieve.*\n",
    "\n",
    "1. **Importing data**\n",
    "\n",
    "2. **Observation on data** *(20pt)*\n",
    "    * The meaning of attributes/features **[I]**\n",
    "    * Distribution and shape? **[I]**\n",
    "    * Is it missing something? If so, remove **[B]** or fill in **[A]** them? Which solution is better? **[A]**\n",
    "    * Is it unbalanced? How to deal with when it is unbalanced? **[I]**\n",
    "    \n",
    "3. **Splitting it into train/dev/test or cross-validation sets** *(5pt)*\n",
    "    * If you want to tackle basic level, you do not need to prepare the test set due to its availability. So please do split data into 80% of training data and 20% of testing data (remember to shuffle).**[B]**\n",
    "    * Is the development set always essential? **[B]**\n",
    "    * Please do cross-validation if you can catch up the deadline. **[A]** (5pt extra)\n",
    "    \n",
    "4. **Pre-processing** *(20pt)*, for examples:\n",
    "    * As for the basic level, encode categorical features as a one-hot numeric array **[B]**\n",
    "    * Standardization **[I]**\n",
    "    * Normalization **[I]**\n",
    "    * Transformations **[I]**\n",
    "    * Feature engineering **[I]**\n",
    "    * Feature selection **[A]**\n",
    "    \n",
    "5. **Training models** *(25pt)*\n",
    "    * As for the basic level, you can give a try with Random Forest or Gaussian Naive Bayes **[B]**\n",
    "    * Choosing the potential method/algorithm **[I]**\n",
    "    * Feeding and optimizing **[I]**\n",
    "    * You are supposed to give at least one try to Neural-Network-related model **[A]**\n",
    "    \n",
    "6. **Evaluating and comparing models** *(10pt)*\n",
    "    * Calculating the accuracy of your model **[B]**\n",
    "    * Choosing your appropriate metrics/measurements for your data **[I]**\n",
    "    * Making an argument expressing your viewpoint on your best model **[A]**\n",
    "\n",
    "7. **Discussion** *(10pt)*\n",
    "    * What did you do? **[B]**\n",
    "    * What are the limitations? **[I]**\n",
    "    * What will you do if you have more time? **[I]**\n",
    "\n",
    "8. **Report & Presentation** *(10pt+)*\n",
    "\n",
    "**The content includes 2 major branches of machine learning**\n",
    "1. _Unsupervised learning_: complete missing data via cluster analysis **[A]**\n",
    "2. _Supervised learning_: classification **[B] + [I] + [A]**\n",
    "\n",
    "**Dealine: ** Please finish off and wrap everything up for your submission within **2 weeks**\n",
    "\n",
    "**Reference**\n",
    "\n",
    "1. http://scikit-learn.org/stable/modules/preprocessing.html\n",
    "2. http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
    "3. http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "4. https://towardsdatascience.com/the-random-forest-algorithm-d457d499ffcd\n",
    "5. https://developers.google.com/machine-learning/crash-course/representation/feature-engineering\n",
    "6. https://developers.google.com/machine-learning/crash-course/representation/cleaning-data\n",
    "7. https://developers.google.com/machine-learning/crash-course/representation/qualities-of-good-features\n",
    "8. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.453.7597&rep=rep1&type=pdf\n",
    "9. http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
    "10. https://developers.google.com/machine-learning/crash-course/classification/accuracy\n",
    "11. http://scikit-learn.org/stable/modules/impute.html#impute\n",
    "12. https://developers.google.com/machine-learning/glossary/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution\n",
    "** Author: ** [fill in your domain name here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T05:27:48.438561Z",
     "start_time": "2018-10-19T05:27:47.563285Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "df_training_data = pd.read_csv(\"data/training_data.csv\")\n",
    "df_testing_data = pd.read_csv(\"data/testing_data.csv\")\n",
    "\n",
    "df_data = df_training_data.append(df_testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T03:25:28.654498Z",
     "start_time": "2018-10-10T03:25:28.600209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4.884200e+04</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>1.896641e+05</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>1079.067626</td>\n",
       "      <td>87.502314</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>1.056040e+05</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>7452.019058</td>\n",
       "      <td>403.004552</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.175505e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.781445e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.376420e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  educational-num  capital-gain  \\\n",
       "count  48842.000000  4.884200e+04     48842.000000  48842.000000   \n",
       "mean      38.643585  1.896641e+05        10.078089   1079.067626   \n",
       "std       13.710510  1.056040e+05         2.570973   7452.019058   \n",
       "min       17.000000  1.228500e+04         1.000000      0.000000   \n",
       "25%       28.000000  1.175505e+05         9.000000      0.000000   \n",
       "50%       37.000000  1.781445e+05        10.000000      0.000000   \n",
       "75%       48.000000  2.376420e+05        12.000000      0.000000   \n",
       "max       90.000000  1.490400e+06        16.000000  99999.000000   \n",
       "\n",
       "       capital-loss  hours-per-week  \n",
       "count  48842.000000    48842.000000  \n",
       "mean      87.502314       40.422382  \n",
       "std      403.004552       12.391444  \n",
       "min        0.000000        1.000000  \n",
       "25%        0.000000       40.000000  \n",
       "50%        0.000000       40.000000  \n",
       "75%        0.000000       45.000000  \n",
       "max     4356.000000       99.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T03:25:28.660414Z",
     "start_time": "2018-10-10T03:25:28.656531Z"
    }
   },
   "outputs": [],
   "source": [
    "Start writing your solution here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data / Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "df_data.reindex(np.random.permutation(df_data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "..............."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
